{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d8debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w=0\n",
    "b=0\n",
    "lr=0.0001\n",
    "num=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1773323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "data=[]\n",
    "for i in range(100):\n",
    "    x=np.random.uniform(-10.,-10.)\n",
    "    eps=np.random.normal(0.,0.1)\n",
    "    y=1.41*x+0.89+eps\n",
    "    data.append([x,y])\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e27f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义loss函数\n",
    "def loss():\n",
    "    loss=0\n",
    "    for i in range(100):\n",
    "        x=data[i,0]\n",
    "        y=data[i,1]\n",
    "        \n",
    "        #计算损失函数和wx+b-y\n",
    "        loss+=pow((w*x+b-y),2)/100\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911b2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义梯度\n",
    "def gradient():\n",
    "    w_gradient=0\n",
    "    b_gradient=0\n",
    "    for i in range(100):\n",
    "        x=data[i,0]\n",
    "        y=data[i,1]\n",
    "        #计算梯度\n",
    "        w_gradient+=(2/100)*((w*x+b)-y)*x\n",
    "        b_gradient+=(2/100)*((w*x+b)-y)\n",
    "    return w_gradient,b_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb4f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_gradient= -263.56398475663656 b_gradient= 26.356398475663656 loss= 166.7288294137729\n",
      "w_gradient= -34.24755540548197 b_gradient= 3.424755540548196 loss= 2.8240670999768294\n",
      "w_gradient= -4.450134005731432 b_gradient= 0.44501340057314315 loss= 0.05662466224230829\n",
      "w_gradient= -0.5782512776311072 b_gradient= 0.057825127763110745 loss= 0.009897907399690323\n",
      "w_gradient= -0.07513808340410223 b_gradient= 0.0075138083404102185 loss= 0.00910895165183085\n",
      "w_gradient= -0.009763457161337627 b_gradient= 0.0009763457161337638 loss= 0.009095630564711132\n",
      "w_gradient= -0.0012686655211276284 b_gradient= 0.0001268665521127602 loss= 0.00909540564542696\n",
      "w_gradient= -0.00016485064439920177 b_gradient= 1.648506443991776e-05 loss= 0.009095401847787623\n",
      "w_gradient= -2.142072476013241e-05 b_gradient= 2.1420724760126664e-06 loss= 0.00909540178366656\n",
      "w_gradient= -2.783413155084055e-06 b_gradient= 2.7834131550996677e-07 loss= 0.009095401782583909\n",
      "w_gradient= -3.6167727653080295e-07 b_gradient= 3.616772765649553e-08 loss= 0.009095401782565626\n",
      "w_gradient= -4.699644403066e-08 b_gradient= 4.699644408389433e-09 loss= 0.009095401782565314\n",
      "w_gradient= -6.10673468390277e-09 b_gradient= 6.106734661134525e-10 loss= 0.009095401782565316\n",
      "w_gradient= -7.934737415726811e-10 b_gradient= 7.934737583778148e-11 loss= 0.009095401782565312\n",
      "w_gradient= -1.0307492272904062e-10 b_gradient= 1.030748961660874e-11 loss= 0.00909540178256532\n",
      "w_gradient= -1.336890233932797e-11 b_gradient= 1.3368875776374745e-12 loss= 0.009095401782565318\n",
      "w_gradient= -1.8580371616283564e-12 b_gradient= 1.858070988736138e-13 loss= 0.009095401782565314\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w_gradient= -1.0764306113131283e-12 b_gradient= 1.0765411999347219e-13 loss= 0.009095401782565318\n",
      "w= 1.304772201765522 b= -0.1304772201765521\n"
     ]
    }
   ],
   "source": [
    "#更新num次梯度以及w和b\n",
    "for j in range(num):\n",
    "    w_gradient=0\n",
    "    b_gradient=0\n",
    "    w_gradient,b_gradient=gradient()\n",
    "    #梯度不断更新\n",
    "    #w(i+1)+=wi-lr*dl/dw\n",
    "    #b(i+1)+=bi-lr*dl/db\n",
    "    w=w-(lr*w_gradient)\n",
    "    b=b-(lr*b_gradient)\n",
    "    if j%100==0:\n",
    "        print('w_gradient=',w_gradient,'b_gradient=',b_gradient,'loss=',loss())\n",
    "\n",
    "print('w=',w,'b=',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041344f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
