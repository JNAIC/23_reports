###唉，又写周报了呢。

###浅浅学了一下《Python神经网络编程》，了解了一下分类器，预测器，神经网络的最简单结构（两层，三层）

###分类器和预测器单一使用，通过调节学习率改善分类器的效果，误差通过求其平方来使其更加精确

###在遇到复杂问题时可使用两个或多个分类器，从中了解到异或，与，非，或

###通过神经的信号处理方式引入s函数（阈值）

###再次深刻领会了矩阵乘法应用的强大之处

###输入层，隐藏层，输出层之间通过权数进行处理，加权之后的数字整合之后再通过s函数得到新的处理数据

###预测值与真实值之差求得误差，反向传播误差来调整权数，不断使得最终结果逼近于真实值

###当层数超过两层时则需要根据上一层的权数来分取误差（反向传递），依然通过矩阵乘法（转制）来实现，但省却了归一化因子

# 有没有哪位佬能解释一下归一化因子省略的问题（是不是经过多次改变权数可忽略这种改变呢？）

###更新权重则无法直接通过公式来求（事实上很难使用公式），则使用梯度下降的方法来求解

# 梯度下降存在的问题

###为避免局部最小点需要增大步长，找到最低点需要减小步长，则需要经过多次尝试才能找到最低点

###之后还涉及到微积分的问题（只好再去学习微积分了）

###类的问题感觉还需要消化一下，感觉到后面有点不太好理解了
