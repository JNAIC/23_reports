反向传播：利用权重，将误差从 输入 向后传播到网络中       
根据权重大小分配误差。然后累加，一点点反向传递  
删除归一化因子效果一样  
转置矩阵：右上方元素编程课左下方元素，左下方元素变成左上方元素，wT(T是上角标）  
矩阵的行数和列数不同也是可以转置的  
保持一个清醒的大脑，学习炫酷的更新权重
QQQQQQQQQ：权重为什么可以是负值？？  
梯度下降：沿着最陡的方向向下
用步进的方式接近答案，优化答案，达到满意的精度  
随机多起点找斜率  
多起点在神经网络中：多个不同的起始链接权重  
调整步长：与梯度大小成比例  
正梯度：减小x，负梯度：增大x，可以画图  
误差函数：多采用目标值和实际值 差的平方  
原因：1.容易代数以计算梯度下降的斜率 2.？QQQQ为什么这种误差函数平滑连续，没有间断和跳跃？ 3.越接近最小值梯度越小，有超调的风险  
微积分：建立关系以表示一种事物如何随着其他事物变化  
训练神经网络：找的一个表达式，优化隐藏层之间的权重找到类似的误差斜率  
学习因子  
符号α是一个因子，这个因子可以调节这些变化的强度，确保不会超调。我们通常称这个因子为学习率。  
这个表达式不仅适用于隐藏层和输出层之间的权重，而且是用于输入曾和隐藏层之间的权重。差值就是误差梯度，我们可以使用上述两个表达式来计算这个误差梯度  
输入变大，激活函数变得平坦，梯度变小，学习能力被限制（神经网络饱和），尽量保持较小的输入  
调整输入值，范围在0.0到1.0，输入0会让学习能力丧失  
我们可以从-1.0到+1.0中随即均匀的选择初始权重  
连接越多，越减少权重的范围：数学家的经验规则：在一个节点传入链接数量的平方根的倒数的大致范围内随机取样，初始化权重。例如，3条链接的权重范围在±0.577  
禁止将初始权重设定为相同的恒定值  

notebook实践了  
群里题做了，好菜，没几道会的，基本不是没思路就是有思路没方法还有因为基础不扎实做错的情况，现在才明白  每周50题有多厉害  
实际对识别数字的应用还没看，也没实践，上周真是说大话了，，，  
致力于尝试在vscode里安装插件，倒是安装上了，但是不会用（菜鸡果然配不上高配  

下周了解一下numpy库，然后刷刷题巩固一下吧，，不做题真不知道多菜  
祝你快乐
