周报 （第二周）

##  阅读相关书籍


    读了100多页的《Python神经网络编程》也叫《Make Your Own Neural Network》
    了解了梯度下降法，是一种常用的优化算法，通过不断调整参数，使得一个目标函数达到最小值或最大值。（沿着梯度的反方向移动参数）

   以及高等代数中 多项式函数与此的联系。

   改进神经网络，意味着通过改变权重减少这种误差。

   因为《Hands-on-Machine-Learning》是全英版的，读起来稍有些费劲，所以没读多少。


## 继续读kaggle
全英读着有点费劲 坎坷了点 


##  机器学习
 
 了解BP学习算法 是目前应用最广泛的神经网络模型之一    其流程 如下
        
  初始化——>为权重赋初值——>求隐藏层 输入层各单元输入——>求目标值和实际输出偏差e——>判断e是否满足需求 （若不满足）——>计算隐藏层单元误差——>求误差梯度——>权值学习——>返回到第三步骤 重复操作



 机器学习包括 
   监督学习(很大工作量）  无监督学习（效果差）弱监督学习

所以弱监督学习是最普遍认可的方式

其中  弱监督学习又包括  半监督学习  迁移学习  强化学习
     

  
