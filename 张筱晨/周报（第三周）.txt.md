周报（第三周）




##继续学习机器学习和神经网络学习

  

   权重的改变取决于激活函数的梯度，小梯度意味着限制神经网络的学习的能力，这就是所谓的饱和神经网络。
   所以要保持小的输入，但也不能太小，计算机处理非常大或非常小的数字时，会丧失精度。

  禁止将初始权重设为相同的恒定值，特别禁止设为0，如果这样做，每个输出节点的输出值相同 误差也会被平分




  ##python


  类和对象
  

类只是定义 对象是所定义类的真正实例。例如类是菜谱书中的蛋糕配方，对象是按照配方做出的一个蛋糕。





 ##用python制作神经网络



 勾勒出神经网络的大概样子  至少有三个函数

· 初始化函数——设定输出层节点 隐藏层节点和输出层节点的数量
· 训练——学习给定训练集样本后，优化权重
· 查询——给定输入，从输出节点给出答案


class neuralNetwork
   def _init_()
        pass
   def train()
        pass
   def query()
        pass


 权重是网络的核心 最重要的部分是链接权重用这些权重来计算前馈信号 反向传播误差 并试图改进网络时优化链接权重本身



X hidden = W input_hidden * I

 以下代码应用了numpy代码库，将连接权重矩阵 W input_hidden 点乘输入矩阵I

hidden_inputs = numpy.dot(self.with, inputs)

  (虽然让我自己写代码写不出来 但我理解这个事）





 ##BP学习算法的缺点



  随着层数加深 训练过程存在严重的梯度扩散现象 当达到最前面的几层时 梯度会逐渐消失 不能引导网络权值的训练 从而导致网络训练过程不能收敛

 （不太懂为什么训练过程会存在严重的梯度扩散现象）

 所以BP学习算法一般只能用于浅层人工神经网络结构（通常为3层）的学习，这就限制了BP学习算法的数据表征能力，影响它的应用

