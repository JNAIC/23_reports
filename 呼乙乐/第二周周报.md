# 第二周周报

## 1这周学习了《python神经网络编程》书的第一章

1.1首先了解了对计算机而言也不是什么都很容易，计算数字可能容易，但是识别面孔可能难。

1.2预测机：当我们不能精确知道一些事情如何运作时，可以使用模型来估计其运作方式，在模型中基于模型和已知真实实例之间的比较，得到模型偏移的误差值，调整参数，改进模型。

1.3：分类器与预测器并无太大差别：学到的就是使用直线将不同性质的事物分开，那得到这个正确的斜率就是关键。

1.4：训练简单的分类器：

​    分类器所使用的是线性函数y=Ax; 期望值t=(A+▲A)x; ▲A=E(误差/x)但是这个改进方法跳跃到每一个新的A值，应该采取节制的调整 调节系数▲A=L(E+X)   L（学习率learning  rate) 可以使用0.5.

1.5有时候一个分类器不足以求解问题： 没学多久呢又发现上次学的有局限性了，

​          AND函数： 在两个条件为真的条件下布尔AND函数才为真，如果一个条件为真的话就是假；

​           OR函数： 一个真或全部为真，那么布尔函数为真。

​     因为他俩的条件跟上两节学的不一样，所以说画的图和线也不一样。但是这两个都只需要一条线。

​           XOR函数：(eXclusive OR )在A或B仅有一个为真但两个输入不同时为真的情况下才为真，两个都为真或假的情况下假。所以说用这个模型的时候就要两条线了。

1.6神经元输出用S型函数y=1/e-1  +x(激发神经元的前提是信号够强超过阈值)，神经元受到多个神经元的输入，同时提供信号给更多的神经元，神经网络是通过调整优化网络内部的链接权重改进输出。W2.3的意思就是与前一层二节点传递给下一层的三节点；

  总结：这周学的篇理论，虚的，下周继续学习！

  

